2016-04-30 15:40:18 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:40:18 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:40:18 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:40:18 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:40:18 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:40:18 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:40:18 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:40:18 [scrapy] INFO: Spider opened
2016-04-30 15:40:18 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:40:38 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:40:38 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 34338,
 'downloader/request_count': 108,
 'downloader/request_method_count/GET': 108,
 'downloader/response_bytes': 1856545,
 'downloader/response_count': 108,
 'downloader/response_status_count/200': 108,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 40, 38, 948835),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 107,
 'response_received_count': 108,
 'scheduler/dequeued': 108,
 'scheduler/dequeued/memory': 108,
 'scheduler/enqueued': 108,
 'scheduler/enqueued/memory': 108,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 7, 40, 18, 993820)}
2016-04-30 15:40:38 [scrapy] INFO: Spider closed (finished)
2016-04-30 15:41:07 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:41:07 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:41:07 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:41:07 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:41:07 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:41:07 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:41:07 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:41:07 [scrapy] INFO: Spider opened
2016-04-30 15:41:07 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:41:07 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:41:07 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/> (referer: None)
2016-04-30 15:41:08 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/2> (referer: http://www.dsqnw.com/)
2016-04-30 15:41:08 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/3> (referer: http://www.dsqnw.com/page/2)
2016-04-30 15:41:08 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/4> (referer: http://www.dsqnw.com/page/3)
2016-04-30 15:41:08 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/5> (referer: http://www.dsqnw.com/page/4)
2016-04-30 15:41:08 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/6> (referer: http://www.dsqnw.com/page/5)
2016-04-30 15:41:09 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/7> (referer: http://www.dsqnw.com/page/6)
2016-04-30 15:41:09 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/8> (referer: http://www.dsqnw.com/page/7)
2016-04-30 15:41:09 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/9> (referer: http://www.dsqnw.com/page/8)
2016-04-30 15:41:09 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/10> (referer: http://www.dsqnw.com/page/9)
2016-04-30 15:41:09 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/11> (referer: http://www.dsqnw.com/page/10)
2016-04-30 15:41:09 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/12> (referer: http://www.dsqnw.com/page/11)
2016-04-30 15:41:09 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/13> (referer: http://www.dsqnw.com/page/12)
2016-04-30 15:41:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/14> (referer: http://www.dsqnw.com/page/13)
2016-04-30 15:41:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/15> (referer: http://www.dsqnw.com/page/14)
2016-04-30 15:41:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/16> (referer: http://www.dsqnw.com/page/15)
2016-04-30 15:41:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/17> (referer: http://www.dsqnw.com/page/16)
2016-04-30 15:41:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/18> (referer: http://www.dsqnw.com/page/17)
2016-04-30 15:41:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/19> (referer: http://www.dsqnw.com/page/18)
2016-04-30 15:41:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/20> (referer: http://www.dsqnw.com/page/19)
2016-04-30 15:41:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/21> (referer: http://www.dsqnw.com/page/20)
2016-04-30 15:41:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/22> (referer: http://www.dsqnw.com/page/21)
2016-04-30 15:41:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/23> (referer: http://www.dsqnw.com/page/22)
2016-04-30 15:41:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/24> (referer: http://www.dsqnw.com/page/23)
2016-04-30 15:41:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/25> (referer: http://www.dsqnw.com/page/24)
2016-04-30 15:41:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/26> (referer: http://www.dsqnw.com/page/25)
2016-04-30 15:41:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/27> (referer: http://www.dsqnw.com/page/26)
2016-04-30 15:41:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/28> (referer: http://www.dsqnw.com/page/27)
2016-04-30 15:41:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/29> (referer: http://www.dsqnw.com/page/28)
2016-04-30 15:41:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/30> (referer: http://www.dsqnw.com/page/29)
2016-04-30 15:41:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/31> (referer: http://www.dsqnw.com/page/30)
2016-04-30 15:41:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/32> (referer: http://www.dsqnw.com/page/31)
2016-04-30 15:41:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/33> (referer: http://www.dsqnw.com/page/32)
2016-04-30 15:41:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/34> (referer: http://www.dsqnw.com/page/33)
2016-04-30 15:41:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/35> (referer: http://www.dsqnw.com/page/34)
2016-04-30 15:41:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/36> (referer: http://www.dsqnw.com/page/35)
2016-04-30 15:41:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/37> (referer: http://www.dsqnw.com/page/36)
2016-04-30 15:41:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/38> (referer: http://www.dsqnw.com/page/37)
2016-04-30 15:41:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/39> (referer: http://www.dsqnw.com/page/38)
2016-04-30 15:41:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/40> (referer: http://www.dsqnw.com/page/39)
2016-04-30 15:41:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/41> (referer: http://www.dsqnw.com/page/40)
2016-04-30 15:41:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/42> (referer: http://www.dsqnw.com/page/41)
2016-04-30 15:41:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/43> (referer: http://www.dsqnw.com/page/42)
2016-04-30 15:41:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/44> (referer: http://www.dsqnw.com/page/43)
2016-04-30 15:41:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/45> (referer: http://www.dsqnw.com/page/44)
2016-04-30 15:41:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/46> (referer: http://www.dsqnw.com/page/45)
2016-04-30 15:41:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/47> (referer: http://www.dsqnw.com/page/46)
2016-04-30 15:41:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/48> (referer: http://www.dsqnw.com/page/47)
2016-04-30 15:41:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/49> (referer: http://www.dsqnw.com/page/48)
2016-04-30 15:41:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/50> (referer: http://www.dsqnw.com/page/49)
2016-04-30 15:41:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/51> (referer: http://www.dsqnw.com/page/50)
2016-04-30 15:41:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/52> (referer: http://www.dsqnw.com/page/51)
2016-04-30 15:41:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/53> (referer: http://www.dsqnw.com/page/52)
2016-04-30 15:41:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/54> (referer: http://www.dsqnw.com/page/53)
2016-04-30 15:41:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/55> (referer: http://www.dsqnw.com/page/54)
2016-04-30 15:41:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/56> (referer: http://www.dsqnw.com/page/55)
2016-04-30 15:41:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/57> (referer: http://www.dsqnw.com/page/56)
2016-04-30 15:41:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/58> (referer: http://www.dsqnw.com/page/57)
2016-04-30 15:41:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/59> (referer: http://www.dsqnw.com/page/58)
2016-04-30 15:41:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/60> (referer: http://www.dsqnw.com/page/59)
2016-04-30 15:41:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/61> (referer: http://www.dsqnw.com/page/60)
2016-04-30 15:41:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/62> (referer: http://www.dsqnw.com/page/61)
2016-04-30 15:41:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/63> (referer: http://www.dsqnw.com/page/62)
2016-04-30 15:41:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/64> (referer: http://www.dsqnw.com/page/63)
2016-04-30 15:41:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/65> (referer: http://www.dsqnw.com/page/64)
2016-04-30 15:41:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/66> (referer: http://www.dsqnw.com/page/65)
2016-04-30 15:41:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/67> (referer: http://www.dsqnw.com/page/66)
2016-04-30 15:41:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/68> (referer: http://www.dsqnw.com/page/67)
2016-04-30 15:41:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/69> (referer: http://www.dsqnw.com/page/68)
2016-04-30 15:41:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/70> (referer: http://www.dsqnw.com/page/69)
2016-04-30 15:41:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/71> (referer: http://www.dsqnw.com/page/70)
2016-04-30 15:41:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/72> (referer: http://www.dsqnw.com/page/71)
2016-04-30 15:41:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/73> (referer: http://www.dsqnw.com/page/72)
2016-04-30 15:41:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/74> (referer: http://www.dsqnw.com/page/73)
2016-04-30 15:41:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/75> (referer: http://www.dsqnw.com/page/74)
2016-04-30 15:41:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/76> (referer: http://www.dsqnw.com/page/75)
2016-04-30 15:41:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/77> (referer: http://www.dsqnw.com/page/76)
2016-04-30 15:41:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/78> (referer: http://www.dsqnw.com/page/77)
2016-04-30 15:41:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/79> (referer: http://www.dsqnw.com/page/78)
2016-04-30 15:41:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/80> (referer: http://www.dsqnw.com/page/79)
2016-04-30 15:41:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/81> (referer: http://www.dsqnw.com/page/80)
2016-04-30 15:41:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/82> (referer: http://www.dsqnw.com/page/81)
2016-04-30 15:41:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/83> (referer: http://www.dsqnw.com/page/82)
2016-04-30 15:41:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/84> (referer: http://www.dsqnw.com/page/83)
2016-04-30 15:41:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/85> (referer: http://www.dsqnw.com/page/84)
2016-04-30 15:41:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/86> (referer: http://www.dsqnw.com/page/85)
2016-04-30 15:41:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/87> (referer: http://www.dsqnw.com/page/86)
2016-04-30 15:41:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/88> (referer: http://www.dsqnw.com/page/87)
2016-04-30 15:41:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/89> (referer: http://www.dsqnw.com/page/88)
2016-04-30 15:41:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/90> (referer: http://www.dsqnw.com/page/89)
2016-04-30 15:41:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/91> (referer: http://www.dsqnw.com/page/90)
2016-04-30 15:41:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/92> (referer: http://www.dsqnw.com/page/91)
2016-04-30 15:41:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/93> (referer: http://www.dsqnw.com/page/92)
2016-04-30 15:41:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/94> (referer: http://www.dsqnw.com/page/93)
2016-04-30 15:41:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/95> (referer: http://www.dsqnw.com/page/94)
2016-04-30 15:41:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/96> (referer: http://www.dsqnw.com/page/95)
2016-04-30 15:41:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/97> (referer: http://www.dsqnw.com/page/96)
2016-04-30 15:41:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/98> (referer: http://www.dsqnw.com/page/97)
2016-04-30 15:41:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/99> (referer: http://www.dsqnw.com/page/98)
2016-04-30 15:41:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/100> (referer: http://www.dsqnw.com/page/99)
2016-04-30 15:41:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/101> (referer: http://www.dsqnw.com/page/100)
2016-04-30 15:41:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/102> (referer: http://www.dsqnw.com/page/101)
2016-04-30 15:41:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/103> (referer: http://www.dsqnw.com/page/102)
2016-04-30 15:41:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/104> (referer: http://www.dsqnw.com/page/103)
2016-04-30 15:41:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/105> (referer: http://www.dsqnw.com/page/104)
2016-04-30 15:41:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/106> (referer: http://www.dsqnw.com/page/105)
2016-04-30 15:41:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/107> (referer: http://www.dsqnw.com/page/106)
2016-04-30 15:41:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/108> (referer: http://www.dsqnw.com/page/107)
2016-04-30 15:41:25 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:41:25 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 34338,
 'downloader/request_count': 108,
 'downloader/request_method_count/GET': 108,
 'downloader/response_bytes': 1856540,
 'downloader/response_count': 108,
 'downloader/response_status_count/200': 108,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 41, 25, 873650),
 'log_count/DEBUG': 109,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 107,
 'response_received_count': 108,
 'scheduler/dequeued': 108,
 'scheduler/dequeued/memory': 108,
 'scheduler/enqueued': 108,
 'scheduler/enqueued/memory': 108,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 7, 41, 7, 917321)}
2016-04-30 15:41:25 [scrapy] INFO: Spider closed (finished)
2016-04-30 15:42:10 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:42:10 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:42:10 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:42:10 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:42:10 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:42:10 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:42:10 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:42:10 [scrapy] INFO: Spider opened
2016-04-30 15:42:10 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:42:10 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:42:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/> (referer: None)
2016-04-30 15:42:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/2> (referer: http://www.dsqnw.com/)
2016-04-30 15:42:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/3> (referer: http://www.dsqnw.com/page/2)
2016-04-30 15:42:10 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/4> (referer: http://www.dsqnw.com/page/3)
2016-04-30 15:42:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/5> (referer: http://www.dsqnw.com/page/4)
2016-04-30 15:42:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/6> (referer: http://www.dsqnw.com/page/5)
2016-04-30 15:42:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/7> (referer: http://www.dsqnw.com/page/6)
2016-04-30 15:42:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/8> (referer: http://www.dsqnw.com/page/7)
2016-04-30 15:42:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/9> (referer: http://www.dsqnw.com/page/8)
2016-04-30 15:42:11 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/10> (referer: http://www.dsqnw.com/page/9)
2016-04-30 15:42:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/11> (referer: http://www.dsqnw.com/page/10)
2016-04-30 15:42:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/12> (referer: http://www.dsqnw.com/page/11)
2016-04-30 15:42:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/13> (referer: http://www.dsqnw.com/page/12)
2016-04-30 15:42:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/14> (referer: http://www.dsqnw.com/page/13)
2016-04-30 15:42:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/15> (referer: http://www.dsqnw.com/page/14)
2016-04-30 15:42:12 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/16> (referer: http://www.dsqnw.com/page/15)
2016-04-30 15:42:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/17> (referer: http://www.dsqnw.com/page/16)
2016-04-30 15:42:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/18> (referer: http://www.dsqnw.com/page/17)
2016-04-30 15:42:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/19> (referer: http://www.dsqnw.com/page/18)
2016-04-30 15:42:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/20> (referer: http://www.dsqnw.com/page/19)
2016-04-30 15:42:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/21> (referer: http://www.dsqnw.com/page/20)
2016-04-30 15:42:13 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/22> (referer: http://www.dsqnw.com/page/21)
2016-04-30 15:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/23> (referer: http://www.dsqnw.com/page/22)
2016-04-30 15:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/24> (referer: http://www.dsqnw.com/page/23)
2016-04-30 15:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/25> (referer: http://www.dsqnw.com/page/24)
2016-04-30 15:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/26> (referer: http://www.dsqnw.com/page/25)
2016-04-30 15:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/27> (referer: http://www.dsqnw.com/page/26)
2016-04-30 15:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/28> (referer: http://www.dsqnw.com/page/27)
2016-04-30 15:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/29> (referer: http://www.dsqnw.com/page/28)
2016-04-30 15:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/30> (referer: http://www.dsqnw.com/page/29)
2016-04-30 15:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/31> (referer: http://www.dsqnw.com/page/30)
2016-04-30 15:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/32> (referer: http://www.dsqnw.com/page/31)
2016-04-30 15:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/33> (referer: http://www.dsqnw.com/page/32)
2016-04-30 15:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/34> (referer: http://www.dsqnw.com/page/33)
2016-04-30 15:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/35> (referer: http://www.dsqnw.com/page/34)
2016-04-30 15:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/36> (referer: http://www.dsqnw.com/page/35)
2016-04-30 15:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/37> (referer: http://www.dsqnw.com/page/36)
2016-04-30 15:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/38> (referer: http://www.dsqnw.com/page/37)
2016-04-30 15:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/39> (referer: http://www.dsqnw.com/page/38)
2016-04-30 15:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/40> (referer: http://www.dsqnw.com/page/39)
2016-04-30 15:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/41> (referer: http://www.dsqnw.com/page/40)
2016-04-30 15:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/42> (referer: http://www.dsqnw.com/page/41)
2016-04-30 15:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/43> (referer: http://www.dsqnw.com/page/42)
2016-04-30 15:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/44> (referer: http://www.dsqnw.com/page/43)
2016-04-30 15:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/45> (referer: http://www.dsqnw.com/page/44)
2016-04-30 15:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/46> (referer: http://www.dsqnw.com/page/45)
2016-04-30 15:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/47> (referer: http://www.dsqnw.com/page/46)
2016-04-30 15:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/48> (referer: http://www.dsqnw.com/page/47)
2016-04-30 15:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/49> (referer: http://www.dsqnw.com/page/48)
2016-04-30 15:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/50> (referer: http://www.dsqnw.com/page/49)
2016-04-30 15:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/51> (referer: http://www.dsqnw.com/page/50)
2016-04-30 15:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/52> (referer: http://www.dsqnw.com/page/51)
2016-04-30 15:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/53> (referer: http://www.dsqnw.com/page/52)
2016-04-30 15:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/54> (referer: http://www.dsqnw.com/page/53)
2016-04-30 15:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/55> (referer: http://www.dsqnw.com/page/54)
2016-04-30 15:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/56> (referer: http://www.dsqnw.com/page/55)
2016-04-30 15:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/57> (referer: http://www.dsqnw.com/page/56)
2016-04-30 15:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/58> (referer: http://www.dsqnw.com/page/57)
2016-04-30 15:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/59> (referer: http://www.dsqnw.com/page/58)
2016-04-30 15:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/60> (referer: http://www.dsqnw.com/page/59)
2016-04-30 15:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/61> (referer: http://www.dsqnw.com/page/60)
2016-04-30 15:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/62> (referer: http://www.dsqnw.com/page/61)
2016-04-30 15:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/63> (referer: http://www.dsqnw.com/page/62)
2016-04-30 15:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/64> (referer: http://www.dsqnw.com/page/63)
2016-04-30 15:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/65> (referer: http://www.dsqnw.com/page/64)
2016-04-30 15:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/66> (referer: http://www.dsqnw.com/page/65)
2016-04-30 15:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/67> (referer: http://www.dsqnw.com/page/66)
2016-04-30 15:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/68> (referer: http://www.dsqnw.com/page/67)
2016-04-30 15:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/69> (referer: http://www.dsqnw.com/page/68)
2016-04-30 15:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/70> (referer: http://www.dsqnw.com/page/69)
2016-04-30 15:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/71> (referer: http://www.dsqnw.com/page/70)
2016-04-30 15:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/72> (referer: http://www.dsqnw.com/page/71)
2016-04-30 15:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/73> (referer: http://www.dsqnw.com/page/72)
2016-04-30 15:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/74> (referer: http://www.dsqnw.com/page/73)
2016-04-30 15:42:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/75> (referer: http://www.dsqnw.com/page/74)
2016-04-30 15:42:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/76> (referer: http://www.dsqnw.com/page/75)
2016-04-30 15:42:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/77> (referer: http://www.dsqnw.com/page/76)
2016-04-30 15:42:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/78> (referer: http://www.dsqnw.com/page/77)
2016-04-30 15:42:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/79> (referer: http://www.dsqnw.com/page/78)
2016-04-30 15:42:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/80> (referer: http://www.dsqnw.com/page/79)
2016-04-30 15:42:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/81> (referer: http://www.dsqnw.com/page/80)
2016-04-30 15:42:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/82> (referer: http://www.dsqnw.com/page/81)
2016-04-30 15:42:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/83> (referer: http://www.dsqnw.com/page/82)
2016-04-30 15:42:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/84> (referer: http://www.dsqnw.com/page/83)
2016-04-30 15:42:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/85> (referer: http://www.dsqnw.com/page/84)
2016-04-30 15:42:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/86> (referer: http://www.dsqnw.com/page/85)
2016-04-30 15:42:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/87> (referer: http://www.dsqnw.com/page/86)
2016-04-30 15:42:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/88> (referer: http://www.dsqnw.com/page/87)
2016-04-30 15:42:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/89> (referer: http://www.dsqnw.com/page/88)
2016-04-30 15:42:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/90> (referer: http://www.dsqnw.com/page/89)
2016-04-30 15:42:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/91> (referer: http://www.dsqnw.com/page/90)
2016-04-30 15:42:26 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/92> (referer: http://www.dsqnw.com/page/91)
2016-04-30 15:42:26 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 15:42:26 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 15:42:26 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 29217,
 'downloader/request_count': 92,
 'downloader/request_method_count/GET': 92,
 'downloader/response_bytes': 1598605,
 'downloader/response_count': 92,
 'downloader/response_status_count/200': 92,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 42, 26, 159170),
 'log_count/DEBUG': 93,
 'log_count/INFO': 8,
 'request_depth_max': 92,
 'response_received_count': 92,
 'scheduler/dequeued': 92,
 'scheduler/dequeued/memory': 92,
 'scheduler/enqueued': 93,
 'scheduler/enqueued/memory': 93,
 'start_time': datetime.datetime(2016, 4, 30, 7, 42, 10, 190913)}
2016-04-30 15:42:26 [scrapy] INFO: Spider closed (shutdown)
2016-04-30 15:43:21 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:43:21 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:43:21 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:43:21 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:43:21 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:43:21 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:43:21 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:43:21 [scrapy] INFO: Spider opened
2016-04-30 15:43:21 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:43:21 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:43:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/> (referer: None)
2016-04-30 15:43:21 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/2> (referer: http://www.dsqnw.com/)
2016-04-30 15:43:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/3> (referer: http://www.dsqnw.com/page/2)
2016-04-30 15:43:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/4> (referer: http://www.dsqnw.com/page/3)
2016-04-30 15:43:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/5> (referer: http://www.dsqnw.com/page/4)
2016-04-30 15:43:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/6> (referer: http://www.dsqnw.com/page/5)
2016-04-30 15:43:22 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/7> (referer: http://www.dsqnw.com/page/6)
2016-04-30 15:43:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/8> (referer: http://www.dsqnw.com/page/7)
2016-04-30 15:43:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/9> (referer: http://www.dsqnw.com/page/8)
2016-04-30 15:43:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/10> (referer: http://www.dsqnw.com/page/9)
2016-04-30 15:43:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/11> (referer: http://www.dsqnw.com/page/10)
2016-04-30 15:43:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/12> (referer: http://www.dsqnw.com/page/11)
2016-04-30 15:43:23 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/13> (referer: http://www.dsqnw.com/page/12)
2016-04-30 15:43:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/14> (referer: http://www.dsqnw.com/page/13)
2016-04-30 15:43:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/15> (referer: http://www.dsqnw.com/page/14)
2016-04-30 15:43:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/16> (referer: http://www.dsqnw.com/page/15)
2016-04-30 15:43:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/17> (referer: http://www.dsqnw.com/page/16)
2016-04-30 15:43:24 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/18> (referer: http://www.dsqnw.com/page/17)
2016-04-30 15:43:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/19> (referer: http://www.dsqnw.com/page/18)
2016-04-30 15:43:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/20> (referer: http://www.dsqnw.com/page/19)
2016-04-30 15:43:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/21> (referer: http://www.dsqnw.com/page/20)
2016-04-30 15:43:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/22> (referer: http://www.dsqnw.com/page/21)
2016-04-30 15:43:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/23> (referer: http://www.dsqnw.com/page/22)
2016-04-30 15:43:25 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/24> (referer: http://www.dsqnw.com/page/23)
2016-04-30 15:43:26 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/25> (referer: http://www.dsqnw.com/page/24)
2016-04-30 15:43:26 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/26> (referer: http://www.dsqnw.com/page/25)
2016-04-30 15:43:26 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/27> (referer: http://www.dsqnw.com/page/26)
2016-04-30 15:43:26 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/28> (referer: http://www.dsqnw.com/page/27)
2016-04-30 15:43:26 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/29> (referer: http://www.dsqnw.com/page/28)
2016-04-30 15:43:26 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/30> (referer: http://www.dsqnw.com/page/29)
2016-04-30 15:43:27 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/31> (referer: http://www.dsqnw.com/page/30)
2016-04-30 15:43:27 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/32> (referer: http://www.dsqnw.com/page/31)
2016-04-30 15:43:27 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/33> (referer: http://www.dsqnw.com/page/32)
2016-04-30 15:43:27 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/34> (referer: http://www.dsqnw.com/page/33)
2016-04-30 15:43:27 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/35> (referer: http://www.dsqnw.com/page/34)
2016-04-30 15:43:28 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/36> (referer: http://www.dsqnw.com/page/35)
2016-04-30 15:43:28 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/37> (referer: http://www.dsqnw.com/page/36)
2016-04-30 15:43:28 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/38> (referer: http://www.dsqnw.com/page/37)
2016-04-30 15:43:28 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/39> (referer: http://www.dsqnw.com/page/38)
2016-04-30 15:43:28 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/40> (referer: http://www.dsqnw.com/page/39)
2016-04-30 15:43:28 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/41> (referer: http://www.dsqnw.com/page/40)
2016-04-30 15:43:29 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/42> (referer: http://www.dsqnw.com/page/41)
2016-04-30 15:43:29 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/43> (referer: http://www.dsqnw.com/page/42)
2016-04-30 15:43:29 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/44> (referer: http://www.dsqnw.com/page/43)
2016-04-30 15:43:29 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/45> (referer: http://www.dsqnw.com/page/44)
2016-04-30 15:43:29 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/46> (referer: http://www.dsqnw.com/page/45)
2016-04-30 15:43:29 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/47> (referer: http://www.dsqnw.com/page/46)
2016-04-30 15:43:30 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/48> (referer: http://www.dsqnw.com/page/47)
2016-04-30 15:43:30 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/49> (referer: http://www.dsqnw.com/page/48)
2016-04-30 15:43:30 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/50> (referer: http://www.dsqnw.com/page/49)
2016-04-30 15:43:30 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/51> (referer: http://www.dsqnw.com/page/50)
2016-04-30 15:43:30 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/52> (referer: http://www.dsqnw.com/page/51)
2016-04-30 15:43:30 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/53> (referer: http://www.dsqnw.com/page/52)
2016-04-30 15:43:31 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/54> (referer: http://www.dsqnw.com/page/53)
2016-04-30 15:43:31 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/55> (referer: http://www.dsqnw.com/page/54)
2016-04-30 15:43:31 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/56> (referer: http://www.dsqnw.com/page/55)
2016-04-30 15:43:31 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/57> (referer: http://www.dsqnw.com/page/56)
2016-04-30 15:43:31 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/58> (referer: http://www.dsqnw.com/page/57)
2016-04-30 15:43:31 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/59> (referer: http://www.dsqnw.com/page/58)
2016-04-30 15:43:32 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/60> (referer: http://www.dsqnw.com/page/59)
2016-04-30 15:43:32 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/61> (referer: http://www.dsqnw.com/page/60)
2016-04-30 15:43:32 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/62> (referer: http://www.dsqnw.com/page/61)
2016-04-30 15:43:32 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/63> (referer: http://www.dsqnw.com/page/62)
2016-04-30 15:43:32 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/64> (referer: http://www.dsqnw.com/page/63)
2016-04-30 15:43:32 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/65> (referer: http://www.dsqnw.com/page/64)
2016-04-30 15:43:33 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/66> (referer: http://www.dsqnw.com/page/65)
2016-04-30 15:43:33 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/67> (referer: http://www.dsqnw.com/page/66)
2016-04-30 15:43:33 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/68> (referer: http://www.dsqnw.com/page/67)
2016-04-30 15:43:33 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/69> (referer: http://www.dsqnw.com/page/68)
2016-04-30 15:43:33 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/70> (referer: http://www.dsqnw.com/page/69)
2016-04-30 15:43:34 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/71> (referer: http://www.dsqnw.com/page/70)
2016-04-30 15:43:34 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/72> (referer: http://www.dsqnw.com/page/71)
2016-04-30 15:43:34 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/73> (referer: http://www.dsqnw.com/page/72)
2016-04-30 15:43:34 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/74> (referer: http://www.dsqnw.com/page/73)
2016-04-30 15:43:34 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/75> (referer: http://www.dsqnw.com/page/74)
2016-04-30 15:43:34 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/76> (referer: http://www.dsqnw.com/page/75)
2016-04-30 15:43:35 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/77> (referer: http://www.dsqnw.com/page/76)
2016-04-30 15:43:35 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/78> (referer: http://www.dsqnw.com/page/77)
2016-04-30 15:43:35 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/79> (referer: http://www.dsqnw.com/page/78)
2016-04-30 15:43:35 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/80> (referer: http://www.dsqnw.com/page/79)
2016-04-30 15:43:35 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/81> (referer: http://www.dsqnw.com/page/80)
2016-04-30 15:43:35 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/82> (referer: http://www.dsqnw.com/page/81)
2016-04-30 15:43:36 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/83> (referer: http://www.dsqnw.com/page/82)
2016-04-30 15:43:36 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/84> (referer: http://www.dsqnw.com/page/83)
2016-04-30 15:43:36 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/85> (referer: http://www.dsqnw.com/page/84)
2016-04-30 15:43:36 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/86> (referer: http://www.dsqnw.com/page/85)
2016-04-30 15:43:36 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/87> (referer: http://www.dsqnw.com/page/86)
2016-04-30 15:43:36 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/88> (referer: http://www.dsqnw.com/page/87)
2016-04-30 15:43:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/89> (referer: http://www.dsqnw.com/page/88)
2016-04-30 15:43:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/90> (referer: http://www.dsqnw.com/page/89)
2016-04-30 15:43:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/91> (referer: http://www.dsqnw.com/page/90)
2016-04-30 15:43:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/92> (referer: http://www.dsqnw.com/page/91)
2016-04-30 15:43:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/93> (referer: http://www.dsqnw.com/page/92)
2016-04-30 15:43:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/94> (referer: http://www.dsqnw.com/page/93)
2016-04-30 15:43:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/95> (referer: http://www.dsqnw.com/page/94)
2016-04-30 15:43:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/96> (referer: http://www.dsqnw.com/page/95)
2016-04-30 15:43:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/97> (referer: http://www.dsqnw.com/page/96)
2016-04-30 15:43:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/98> (referer: http://www.dsqnw.com/page/97)
2016-04-30 15:43:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/99> (referer: http://www.dsqnw.com/page/98)
2016-04-30 15:43:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/100> (referer: http://www.dsqnw.com/page/99)
2016-04-30 15:43:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/101> (referer: http://www.dsqnw.com/page/100)
2016-04-30 15:43:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/102> (referer: http://www.dsqnw.com/page/101)
2016-04-30 15:43:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/103> (referer: http://www.dsqnw.com/page/102)
2016-04-30 15:43:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/104> (referer: http://www.dsqnw.com/page/103)
2016-04-30 15:43:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/105> (referer: http://www.dsqnw.com/page/104)
2016-04-30 15:43:40 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/106> (referer: http://www.dsqnw.com/page/105)
2016-04-30 15:43:40 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/107> (referer: http://www.dsqnw.com/page/106)
2016-04-30 15:43:40 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/108> (referer: http://www.dsqnw.com/page/107)
2016-04-30 15:43:40 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:43:40 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 34338,
 'downloader/request_count': 108,
 'downloader/request_method_count/GET': 108,
 'downloader/response_bytes': 1856545,
 'downloader/response_count': 108,
 'downloader/response_status_count/200': 108,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 43, 40, 531232),
 'log_count/DEBUG': 109,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 107,
 'response_received_count': 108,
 'scheduler/dequeued': 108,
 'scheduler/dequeued/memory': 108,
 'scheduler/enqueued': 108,
 'scheduler/enqueued/memory': 108,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 7, 43, 21, 540610)}
2016-04-30 15:43:40 [scrapy] INFO: Spider closed (finished)
2016-04-30 15:44:37 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:44:37 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:44:37 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:44:37 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:44:37 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:44:37 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:44:37 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:44:37 [scrapy] INFO: Spider opened
2016-04-30 15:44:37 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:44:37 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:44:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/> (referer: None)
2016-04-30 15:44:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/2> (referer: http://www.dsqnw.com/)
2016-04-30 15:44:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/3> (referer: http://www.dsqnw.com/page/2)
2016-04-30 15:44:37 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/4> (referer: http://www.dsqnw.com/page/3)
2016-04-30 15:44:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/5> (referer: http://www.dsqnw.com/page/4)
2016-04-30 15:44:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/6> (referer: http://www.dsqnw.com/page/5)
2016-04-30 15:44:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/7> (referer: http://www.dsqnw.com/page/6)
2016-04-30 15:44:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/8> (referer: http://www.dsqnw.com/page/7)
2016-04-30 15:44:38 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/9> (referer: http://www.dsqnw.com/page/8)
2016-04-30 15:44:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/10> (referer: http://www.dsqnw.com/page/9)
2016-04-30 15:44:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/11> (referer: http://www.dsqnw.com/page/10)
2016-04-30 15:44:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/12> (referer: http://www.dsqnw.com/page/11)
2016-04-30 15:44:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/13> (referer: http://www.dsqnw.com/page/12)
2016-04-30 15:44:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/14> (referer: http://www.dsqnw.com/page/13)
2016-04-30 15:44:39 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/15> (referer: http://www.dsqnw.com/page/14)
2016-04-30 15:44:40 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/16> (referer: http://www.dsqnw.com/page/15)
2016-04-30 15:44:40 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/17> (referer: http://www.dsqnw.com/page/16)
2016-04-30 15:44:40 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/18> (referer: http://www.dsqnw.com/page/17)
2016-04-30 15:44:40 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/19> (referer: http://www.dsqnw.com/page/18)
2016-04-30 15:44:40 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/20> (referer: http://www.dsqnw.com/page/19)
2016-04-30 15:44:40 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/21> (referer: http://www.dsqnw.com/page/20)
2016-04-30 15:44:41 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/22> (referer: http://www.dsqnw.com/page/21)
2016-04-30 15:44:41 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/23> (referer: http://www.dsqnw.com/page/22)
2016-04-30 15:44:41 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/24> (referer: http://www.dsqnw.com/page/23)
2016-04-30 15:44:41 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/25> (referer: http://www.dsqnw.com/page/24)
2016-04-30 15:44:41 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/26> (referer: http://www.dsqnw.com/page/25)
2016-04-30 15:44:41 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/27> (referer: http://www.dsqnw.com/page/26)
2016-04-30 15:44:42 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/28> (referer: http://www.dsqnw.com/page/27)
2016-04-30 15:44:42 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/29> (referer: http://www.dsqnw.com/page/28)
2016-04-30 15:44:42 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/30> (referer: http://www.dsqnw.com/page/29)
2016-04-30 15:44:42 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/31> (referer: http://www.dsqnw.com/page/30)
2016-04-30 15:44:42 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/32> (referer: http://www.dsqnw.com/page/31)
2016-04-30 15:44:42 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/33> (referer: http://www.dsqnw.com/page/32)
2016-04-30 15:44:43 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/34> (referer: http://www.dsqnw.com/page/33)
2016-04-30 15:44:43 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/35> (referer: http://www.dsqnw.com/page/34)
2016-04-30 15:44:43 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/36> (referer: http://www.dsqnw.com/page/35)
2016-04-30 15:44:43 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/37> (referer: http://www.dsqnw.com/page/36)
2016-04-30 15:44:43 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/38> (referer: http://www.dsqnw.com/page/37)
2016-04-30 15:44:43 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/39> (referer: http://www.dsqnw.com/page/38)
2016-04-30 15:44:44 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/40> (referer: http://www.dsqnw.com/page/39)
2016-04-30 15:44:44 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/41> (referer: http://www.dsqnw.com/page/40)
2016-04-30 15:44:44 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/42> (referer: http://www.dsqnw.com/page/41)
2016-04-30 15:44:44 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/43> (referer: http://www.dsqnw.com/page/42)
2016-04-30 15:44:44 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/44> (referer: http://www.dsqnw.com/page/43)
2016-04-30 15:44:44 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/45> (referer: http://www.dsqnw.com/page/44)
2016-04-30 15:44:45 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/46> (referer: http://www.dsqnw.com/page/45)
2016-04-30 15:44:45 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/47> (referer: http://www.dsqnw.com/page/46)
2016-04-30 15:44:45 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/48> (referer: http://www.dsqnw.com/page/47)
2016-04-30 15:44:45 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/49> (referer: http://www.dsqnw.com/page/48)
2016-04-30 15:44:45 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/50> (referer: http://www.dsqnw.com/page/49)
2016-04-30 15:44:45 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/51> (referer: http://www.dsqnw.com/page/50)
2016-04-30 15:44:46 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/52> (referer: http://www.dsqnw.com/page/51)
2016-04-30 15:44:46 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/53> (referer: http://www.dsqnw.com/page/52)
2016-04-30 15:44:46 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/54> (referer: http://www.dsqnw.com/page/53)
2016-04-30 15:44:46 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/55> (referer: http://www.dsqnw.com/page/54)
2016-04-30 15:44:46 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/56> (referer: http://www.dsqnw.com/page/55)
2016-04-30 15:44:46 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/57> (referer: http://www.dsqnw.com/page/56)
2016-04-30 15:44:47 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/58> (referer: http://www.dsqnw.com/page/57)
2016-04-30 15:44:47 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/59> (referer: http://www.dsqnw.com/page/58)
2016-04-30 15:44:47 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/60> (referer: http://www.dsqnw.com/page/59)
2016-04-30 15:44:47 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/61> (referer: http://www.dsqnw.com/page/60)
2016-04-30 15:44:47 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/62> (referer: http://www.dsqnw.com/page/61)
2016-04-30 15:44:47 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/63> (referer: http://www.dsqnw.com/page/62)
2016-04-30 15:44:48 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/64> (referer: http://www.dsqnw.com/page/63)
2016-04-30 15:44:48 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/65> (referer: http://www.dsqnw.com/page/64)
2016-04-30 15:44:48 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/66> (referer: http://www.dsqnw.com/page/65)
2016-04-30 15:44:48 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/67> (referer: http://www.dsqnw.com/page/66)
2016-04-30 15:44:48 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/68> (referer: http://www.dsqnw.com/page/67)
2016-04-30 15:44:48 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/69> (referer: http://www.dsqnw.com/page/68)
2016-04-30 15:44:49 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/70> (referer: http://www.dsqnw.com/page/69)
2016-04-30 15:44:49 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/71> (referer: http://www.dsqnw.com/page/70)
2016-04-30 15:44:49 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/72> (referer: http://www.dsqnw.com/page/71)
2016-04-30 15:44:49 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/73> (referer: http://www.dsqnw.com/page/72)
2016-04-30 15:44:49 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/74> (referer: http://www.dsqnw.com/page/73)
2016-04-30 15:44:49 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/75> (referer: http://www.dsqnw.com/page/74)
2016-04-30 15:44:50 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/76> (referer: http://www.dsqnw.com/page/75)
2016-04-30 15:44:50 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/77> (referer: http://www.dsqnw.com/page/76)
2016-04-30 15:44:50 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/78> (referer: http://www.dsqnw.com/page/77)
2016-04-30 15:44:50 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/79> (referer: http://www.dsqnw.com/page/78)
2016-04-30 15:44:50 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/80> (referer: http://www.dsqnw.com/page/79)
2016-04-30 15:44:50 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/81> (referer: http://www.dsqnw.com/page/80)
2016-04-30 15:44:51 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/82> (referer: http://www.dsqnw.com/page/81)
2016-04-30 15:44:51 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/83> (referer: http://www.dsqnw.com/page/82)
2016-04-30 15:44:51 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/84> (referer: http://www.dsqnw.com/page/83)
2016-04-30 15:44:51 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/85> (referer: http://www.dsqnw.com/page/84)
2016-04-30 15:44:51 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/86> (referer: http://www.dsqnw.com/page/85)
2016-04-30 15:44:52 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/87> (referer: http://www.dsqnw.com/page/86)
2016-04-30 15:44:52 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/88> (referer: http://www.dsqnw.com/page/87)
2016-04-30 15:44:52 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/89> (referer: http://www.dsqnw.com/page/88)
2016-04-30 15:44:52 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/90> (referer: http://www.dsqnw.com/page/89)
2016-04-30 15:44:52 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/91> (referer: http://www.dsqnw.com/page/90)
2016-04-30 15:44:52 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/92> (referer: http://www.dsqnw.com/page/91)
2016-04-30 15:44:53 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/93> (referer: http://www.dsqnw.com/page/92)
2016-04-30 15:44:53 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/94> (referer: http://www.dsqnw.com/page/93)
2016-04-30 15:44:53 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/95> (referer: http://www.dsqnw.com/page/94)
2016-04-30 15:44:53 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/96> (referer: http://www.dsqnw.com/page/95)
2016-04-30 15:44:53 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/97> (referer: http://www.dsqnw.com/page/96)
2016-04-30 15:44:53 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/98> (referer: http://www.dsqnw.com/page/97)
2016-04-30 15:44:54 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/99> (referer: http://www.dsqnw.com/page/98)
2016-04-30 15:44:54 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/100> (referer: http://www.dsqnw.com/page/99)
2016-04-30 15:44:54 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/101> (referer: http://www.dsqnw.com/page/100)
2016-04-30 15:44:54 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/102> (referer: http://www.dsqnw.com/page/101)
2016-04-30 15:44:54 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/103> (referer: http://www.dsqnw.com/page/102)
2016-04-30 15:44:55 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/104> (referer: http://www.dsqnw.com/page/103)
2016-04-30 15:44:55 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/105> (referer: http://www.dsqnw.com/page/104)
2016-04-30 15:44:55 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/106> (referer: http://www.dsqnw.com/page/105)
2016-04-30 15:44:55 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/107> (referer: http://www.dsqnw.com/page/106)
2016-04-30 15:44:55 [scrapy] DEBUG: Crawled (200) <GET http://www.dsqnw.com/page/108> (referer: http://www.dsqnw.com/page/107)
2016-04-30 15:44:55 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:44:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 34338,
 'downloader/request_count': 108,
 'downloader/request_method_count/GET': 108,
 'downloader/response_bytes': 1856533,
 'downloader/response_count': 108,
 'downloader/response_status_count/200': 108,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 44, 55, 939655),
 'log_count/DEBUG': 109,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 107,
 'response_received_count': 108,
 'scheduler/dequeued': 108,
 'scheduler/dequeued/memory': 108,
 'scheduler/enqueued': 108,
 'scheduler/enqueued/memory': 108,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 7, 44, 37, 270523)}
2016-04-30 15:44:55 [scrapy] INFO: Spider closed (finished)
2016-04-30 15:46:56 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:46:56 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:46:56 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:46:56 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:46:56 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:46:56 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:46:56 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:46:56 [scrapy] INFO: Spider opened
2016-04-30 15:46:56 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:46:56 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:46:56 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net> (referer: None)
2016-04-30 15:46:56 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/2> (referer: http://fuliba.net)
2016-04-30 15:46:56 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/3> (referer: http://fuliba.net/page/2)
2016-04-30 15:46:57 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/4> (referer: http://fuliba.net/page/3)
2016-04-30 15:46:57 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/5> (referer: http://fuliba.net/page/4)
2016-04-30 15:46:57 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/6> (referer: http://fuliba.net/page/5)
2016-04-30 15:46:57 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/7> (referer: http://fuliba.net/page/6)
2016-04-30 15:46:57 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/8> (referer: http://fuliba.net/page/7)
2016-04-30 15:46:57 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/9> (referer: http://fuliba.net/page/8)
2016-04-30 15:46:57 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/10> (referer: http://fuliba.net/page/9)
2016-04-30 15:46:58 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/11> (referer: http://fuliba.net/page/10)
2016-04-30 15:46:58 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/12> (referer: http://fuliba.net/page/11)
2016-04-30 15:46:58 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/13> (referer: http://fuliba.net/page/12)
2016-04-30 15:46:58 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/14> (referer: http://fuliba.net/page/13)
2016-04-30 15:46:58 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/15> (referer: http://fuliba.net/page/14)
2016-04-30 15:46:58 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/16> (referer: http://fuliba.net/page/15)
2016-04-30 15:46:58 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/17> (referer: http://fuliba.net/page/16)
2016-04-30 15:46:59 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/18> (referer: http://fuliba.net/page/17)
2016-04-30 15:46:59 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/19> (referer: http://fuliba.net/page/18)
2016-04-30 15:46:59 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/20> (referer: http://fuliba.net/page/19)
2016-04-30 15:46:59 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/21> (referer: http://fuliba.net/page/20)
2016-04-30 15:46:59 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/22> (referer: http://fuliba.net/page/21)
2016-04-30 15:46:59 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/23> (referer: http://fuliba.net/page/22)
2016-04-30 15:47:00 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/24> (referer: http://fuliba.net/page/23)
2016-04-30 15:47:00 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/25> (referer: http://fuliba.net/page/24)
2016-04-30 15:47:00 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/26> (referer: http://fuliba.net/page/25)
2016-04-30 15:47:00 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/27> (referer: http://fuliba.net/page/26)
2016-04-30 15:47:00 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/28> (referer: http://fuliba.net/page/27)
2016-04-30 15:47:00 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/29> (referer: http://fuliba.net/page/28)
2016-04-30 15:47:00 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/30> (referer: http://fuliba.net/page/29)
2016-04-30 15:47:01 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/31> (referer: http://fuliba.net/page/30)
2016-04-30 15:47:01 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/32> (referer: http://fuliba.net/page/31)
2016-04-30 15:47:01 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/33> (referer: http://fuliba.net/page/32)
2016-04-30 15:47:01 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/34> (referer: http://fuliba.net/page/33)
2016-04-30 15:47:01 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/35> (referer: http://fuliba.net/page/34)
2016-04-30 15:47:01 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/36> (referer: http://fuliba.net/page/35)
2016-04-30 15:47:01 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/37> (referer: http://fuliba.net/page/36)
2016-04-30 15:47:02 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/38> (referer: http://fuliba.net/page/37)
2016-04-30 15:47:02 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/39> (referer: http://fuliba.net/page/38)
2016-04-30 15:47:02 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/40> (referer: http://fuliba.net/page/39)
2016-04-30 15:47:02 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/41> (referer: http://fuliba.net/page/40)
2016-04-30 15:47:02 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/42> (referer: http://fuliba.net/page/41)
2016-04-30 15:47:02 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/43> (referer: http://fuliba.net/page/42)
2016-04-30 15:47:02 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/44> (referer: http://fuliba.net/page/43)
2016-04-30 15:47:03 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/45> (referer: http://fuliba.net/page/44)
2016-04-30 15:47:03 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/46> (referer: http://fuliba.net/page/45)
2016-04-30 15:47:03 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/47> (referer: http://fuliba.net/page/46)
2016-04-30 15:47:03 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/48> (referer: http://fuliba.net/page/47)
2016-04-30 15:47:03 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/49> (referer: http://fuliba.net/page/48)
2016-04-30 15:47:03 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/50> (referer: http://fuliba.net/page/49)
2016-04-30 15:47:04 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/51> (referer: http://fuliba.net/page/50)
2016-04-30 15:47:04 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/52> (referer: http://fuliba.net/page/51)
2016-04-30 15:47:04 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/53> (referer: http://fuliba.net/page/52)
2016-04-30 15:47:04 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/54> (referer: http://fuliba.net/page/53)
2016-04-30 15:47:04 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/55> (referer: http://fuliba.net/page/54)
2016-04-30 15:47:04 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/56> (referer: http://fuliba.net/page/55)
2016-04-30 15:47:04 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/57> (referer: http://fuliba.net/page/56)
2016-04-30 15:47:05 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/58> (referer: http://fuliba.net/page/57)
2016-04-30 15:47:05 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/59> (referer: http://fuliba.net/page/58)
2016-04-30 15:47:05 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/60> (referer: http://fuliba.net/page/59)
2016-04-30 15:47:05 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/61> (referer: http://fuliba.net/page/60)
2016-04-30 15:47:05 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/62> (referer: http://fuliba.net/page/61)
2016-04-30 15:47:05 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/63> (referer: http://fuliba.net/page/62)
2016-04-30 15:47:05 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/64> (referer: http://fuliba.net/page/63)
2016-04-30 15:47:06 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/65> (referer: http://fuliba.net/page/64)
2016-04-30 15:47:06 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/66> (referer: http://fuliba.net/page/65)
2016-04-30 15:47:06 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/67> (referer: http://fuliba.net/page/66)
2016-04-30 15:47:06 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/68> (referer: http://fuliba.net/page/67)
2016-04-30 15:47:06 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/69> (referer: http://fuliba.net/page/68)
2016-04-30 15:47:06 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/70> (referer: http://fuliba.net/page/69)
2016-04-30 15:47:06 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/71> (referer: http://fuliba.net/page/70)
2016-04-30 15:47:07 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/72> (referer: http://fuliba.net/page/71)
2016-04-30 15:47:07 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/73> (referer: http://fuliba.net/page/72)
2016-04-30 15:47:07 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/74> (referer: http://fuliba.net/page/73)
2016-04-30 15:47:07 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/75> (referer: http://fuliba.net/page/74)
2016-04-30 15:47:07 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/76> (referer: http://fuliba.net/page/75)
2016-04-30 15:47:07 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/77> (referer: http://fuliba.net/page/76)
2016-04-30 15:47:08 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/78> (referer: http://fuliba.net/page/77)
2016-04-30 15:47:08 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/79> (referer: http://fuliba.net/page/78)
2016-04-30 15:47:08 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/80> (referer: http://fuliba.net/page/79)
2016-04-30 15:47:08 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/81> (referer: http://fuliba.net/page/80)
2016-04-30 15:47:08 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/82> (referer: http://fuliba.net/page/81)
2016-04-30 15:47:08 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/83> (referer: http://fuliba.net/page/82)
2016-04-30 15:47:08 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/84> (referer: http://fuliba.net/page/83)
2016-04-30 15:47:09 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/85> (referer: http://fuliba.net/page/84)
2016-04-30 15:47:09 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/86> (referer: http://fuliba.net/page/85)
2016-04-30 15:47:09 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/87> (referer: http://fuliba.net/page/86)
2016-04-30 15:47:09 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/88> (referer: http://fuliba.net/page/87)
2016-04-30 15:47:09 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/89> (referer: http://fuliba.net/page/88)
2016-04-30 15:47:09 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/90> (referer: http://fuliba.net/page/89)
2016-04-30 15:47:09 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/91> (referer: http://fuliba.net/page/90)
2016-04-30 15:47:10 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/92> (referer: http://fuliba.net/page/91)
2016-04-30 15:47:10 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/93> (referer: http://fuliba.net/page/92)
2016-04-30 15:47:10 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/94> (referer: http://fuliba.net/page/93)
2016-04-30 15:47:10 [scrapy] DEBUG: Crawled (200) <GET http://fuliba.net/page/95> (referer: http://fuliba.net/page/94)
2016-04-30 15:47:10 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:47:10 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 23778,
 'downloader/request_count': 95,
 'downloader/request_method_count/GET': 95,
 'downloader/response_bytes': 1755581,
 'downloader/response_count': 95,
 'downloader/response_status_count/200': 95,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 47, 10, 658648),
 'log_count/DEBUG': 96,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 94,
 'response_received_count': 95,
 'scheduler/dequeued': 95,
 'scheduler/dequeued/memory': 95,
 'scheduler/enqueued': 95,
 'scheduler/enqueued/memory': 95,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 7, 46, 56, 490644)}
2016-04-30 15:47:10 [scrapy] INFO: Spider closed (finished)
2016-04-30 15:50:09 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:50:09 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:50:09 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:50:21 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:50:21 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:50:21 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:50:21 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:50:21 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:50:21 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:50:21 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:50:21 [scrapy] INFO: Spider opened
2016-04-30 15:50:21 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:50:21 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:50:21 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net> (referer: None)
2016-04-30 15:50:21 [scrapy] ERROR: Spider error processing <GET http://zhainanba.net> (referer: None)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiao/project/fuli/src/fuli_spiders/fuli_spiders/spiders/zhainanba.py", line 37, in parse
    img=img, tags=tags, date=date, category=category)
  File "/Users/xiao/project/fuli/src/fuli_spiders/fuli_spiders/spiders/base.py", line 59, in save
    kwargs['ch_src'] = self.__class__.ch_name
AttributeError: type object 'ZhaiNanBa' has no attribute 'ch_name'
2016-04-30 15:50:21 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:50:21 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 211,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 18193,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 50, 21, 788865),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 7, 50, 21, 603164)}
2016-04-30 15:50:21 [scrapy] INFO: Spider closed (finished)
2016-04-30 15:50:48 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:50:48 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:50:48 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:50:48 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:50:48 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:50:48 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:50:48 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:50:48 [scrapy] INFO: Spider opened
2016-04-30 15:50:48 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:50:48 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:50:48 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net> (referer: None)
2016-04-30 15:50:48 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/2> (referer: http://zhainanba.net)
2016-04-30 15:50:49 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/3> (referer: http://zhainanba.net/page/2)
2016-04-30 15:50:49 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/4> (referer: http://zhainanba.net/page/3)
2016-04-30 15:50:49 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/5> (referer: http://zhainanba.net/page/4)
2016-04-30 15:50:49 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/6> (referer: http://zhainanba.net/page/5)
2016-04-30 15:50:49 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/7> (referer: http://zhainanba.net/page/6)
2016-04-30 15:50:50 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/8> (referer: http://zhainanba.net/page/7)
2016-04-30 15:50:50 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/9> (referer: http://zhainanba.net/page/8)
2016-04-30 15:50:50 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/10> (referer: http://zhainanba.net/page/9)
2016-04-30 15:50:50 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/11> (referer: http://zhainanba.net/page/10)
2016-04-30 15:50:50 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/12> (referer: http://zhainanba.net/page/11)
2016-04-30 15:50:51 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/13> (referer: http://zhainanba.net/page/12)
2016-04-30 15:50:51 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/14> (referer: http://zhainanba.net/page/13)
2016-04-30 15:50:51 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/15> (referer: http://zhainanba.net/page/14)
2016-04-30 15:50:51 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/16> (referer: http://zhainanba.net/page/15)
2016-04-30 15:50:52 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/17> (referer: http://zhainanba.net/page/16)
2016-04-30 15:50:52 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/18> (referer: http://zhainanba.net/page/17)
2016-04-30 15:50:52 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/19> (referer: http://zhainanba.net/page/18)
2016-04-30 15:50:52 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/20> (referer: http://zhainanba.net/page/19)
2016-04-30 15:50:53 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/21> (referer: http://zhainanba.net/page/20)
2016-04-30 15:50:53 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/22> (referer: http://zhainanba.net/page/21)
2016-04-30 15:50:54 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/23> (referer: http://zhainanba.net/page/22)
2016-04-30 15:50:56 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/24> (referer: http://zhainanba.net/page/23)
2016-04-30 15:50:56 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/25> (referer: http://zhainanba.net/page/24)
2016-04-30 15:50:57 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/26> (referer: http://zhainanba.net/page/25)
2016-04-30 15:50:58 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/27> (referer: http://zhainanba.net/page/26)
2016-04-30 15:50:58 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/28> (referer: http://zhainanba.net/page/27)
2016-04-30 15:50:59 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/29> (referer: http://zhainanba.net/page/28)
2016-04-30 15:51:00 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/30> (referer: http://zhainanba.net/page/29)
2016-04-30 15:51:00 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/31> (referer: http://zhainanba.net/page/30)
2016-04-30 15:51:01 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/32> (referer: http://zhainanba.net/page/31)
2016-04-30 15:51:02 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/33> (referer: http://zhainanba.net/page/32)
2016-04-30 15:51:02 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/34> (referer: http://zhainanba.net/page/33)
2016-04-30 15:51:03 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/35> (referer: http://zhainanba.net/page/34)
2016-04-30 15:51:04 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/36> (referer: http://zhainanba.net/page/35)
2016-04-30 15:51:04 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/37> (referer: http://zhainanba.net/page/36)
2016-04-30 15:51:05 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/38> (referer: http://zhainanba.net/page/37)
2016-04-30 15:51:06 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/39> (referer: http://zhainanba.net/page/38)
2016-04-30 15:51:07 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/40> (referer: http://zhainanba.net/page/39)
2016-04-30 15:51:08 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/41> (referer: http://zhainanba.net/page/40)
2016-04-30 15:51:09 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/42> (referer: http://zhainanba.net/page/41)
2016-04-30 15:51:10 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/43> (referer: http://zhainanba.net/page/42)
2016-04-30 15:51:11 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/44> (referer: http://zhainanba.net/page/43)
2016-04-30 15:51:12 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/45> (referer: http://zhainanba.net/page/44)
2016-04-30 15:51:13 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/46> (referer: http://zhainanba.net/page/45)
2016-04-30 15:51:14 [scrapy] DEBUG: Crawled (200) <GET http://zhainanba.net/page/47> (referer: http://zhainanba.net/page/46)
2016-04-30 15:51:14 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:51:14 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 12009,
 'downloader/request_count': 47,
 'downloader/request_method_count/GET': 47,
 'downloader/response_bytes': 841841,
 'downloader/response_count': 47,
 'downloader/response_status_count/200': 47,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 51, 14, 442017),
 'log_count/DEBUG': 48,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 46,
 'response_received_count': 47,
 'scheduler/dequeued': 47,
 'scheduler/dequeued/memory': 47,
 'scheduler/enqueued': 47,
 'scheduler/enqueued/memory': 47,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 7, 50, 48, 504952)}
2016-04-30 15:51:14 [scrapy] INFO: Spider closed (finished)
2016-04-30 15:55:10 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:55:10 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:55:10 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:55:44 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:55:44 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:55:44 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:55:44 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:55:44 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:55:44 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:55:44 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:55:44 [scrapy] INFO: Spider opened
2016-04-30 15:55:44 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:55:44 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:55:44 [scrapy] DEBUG: Retrying <GET http://www.fulidang.com/page/1> (failed 1 times): 503 Service Unavailable
2016-04-30 15:55:44 [scrapy] DEBUG: Retrying <GET http://www.fulidang.com/page/1> (failed 2 times): 503 Service Unavailable
2016-04-30 15:55:44 [scrapy] DEBUG: Gave up retrying <GET http://www.fulidang.com/page/1> (failed 3 times): 503 Service Unavailable
2016-04-30 15:55:44 [scrapy] DEBUG: Crawled (503) <GET http://www.fulidang.com/page/1> (referer: None)
2016-04-30 15:55:44 [scrapy] DEBUG: Ignoring response <503 http://www.fulidang.com/page/1>: HTTP status code is not handled or not allowed
2016-04-30 15:55:44 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:55:44 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 784,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 11595,
 'downloader/response_count': 3,
 'downloader/response_status_count/503': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 55, 44, 465788),
 'log_count/DEBUG': 6,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2016, 4, 30, 7, 55, 44, 258514)}
2016-04-30 15:55:44 [scrapy] INFO: Spider closed (finished)
2016-04-30 15:56:32 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:56:32 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:56:32 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:56:32 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:56:32 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:56:32 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:56:32 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:56:32 [scrapy] INFO: Spider opened
2016-04-30 15:56:32 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:56:32 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:56:32 [scrapy] DEBUG: Retrying <GET http://www.fulidang.com/page/1> (failed 1 times): 503 Service Unavailable
2016-04-30 15:56:32 [scrapy] DEBUG: Retrying <GET http://www.fulidang.com/page/1> (failed 2 times): 503 Service Unavailable
2016-04-30 15:56:32 [scrapy] DEBUG: Gave up retrying <GET http://www.fulidang.com/page/1> (failed 3 times): 503 Service Unavailable
2016-04-30 15:56:32 [scrapy] DEBUG: Crawled (503) <GET http://www.fulidang.com/page/1> (referer: None)
2016-04-30 15:56:32 [scrapy] DEBUG: Ignoring response <503 http://www.fulidang.com/page/1>: HTTP status code is not handled or not allowed
2016-04-30 15:56:32 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:56:32 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 784,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 10888,
 'downloader/response_count': 3,
 'downloader/response_status_count/503': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 56, 32, 629047),
 'log_count/DEBUG': 6,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2016, 4, 30, 7, 56, 32, 416433)}
2016-04-30 15:56:32 [scrapy] INFO: Spider closed (finished)
2016-04-30 15:59:27 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 15:59:27 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 15:59:27 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 15:59:27 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 15:59:27 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 15:59:27 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 15:59:27 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 15:59:27 [scrapy] INFO: Spider opened
2016-04-30 15:59:27 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 15:59:27 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 15:59:28 [scrapy] DEBUG: Retrying <GET http://www.fulidang.com/page/1> (failed 1 times): 503 Service Unavailable
2016-04-30 15:59:28 [scrapy] DEBUG: Retrying <GET http://www.fulidang.com/page/1> (failed 2 times): 503 Service Unavailable
2016-04-30 15:59:28 [scrapy] DEBUG: Gave up retrying <GET http://www.fulidang.com/page/1> (failed 3 times): 503 Service Unavailable
2016-04-30 15:59:28 [scrapy] DEBUG: Crawled (503) <GET http://www.fulidang.com/page/1> (referer: None)
2016-04-30 15:59:28 [scrapy] DEBUG: Ignoring response <503 http://www.fulidang.com/page/1>: HTTP status code is not handled or not allowed
2016-04-30 15:59:28 [scrapy] INFO: Closing spider (finished)
2016-04-30 15:59:28 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 844,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 11581,
 'downloader/response_count': 3,
 'downloader/response_status_count/503': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 7, 59, 28, 245930),
 'log_count/DEBUG': 6,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2016, 4, 30, 7, 59, 27, 999121)}
2016-04-30 15:59:28 [scrapy] INFO: Spider closed (finished)
2016-04-30 16:01:02 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 16:01:02 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 16:01:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 16:01:04 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 16:01:04 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 16:01:04 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 16:01:12 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 16:01:12 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 16:01:12 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 16:01:12 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 16:01:12 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 16:01:12 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 16:01:12 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 16:01:12 [scrapy] INFO: Spider opened
2016-04-30 16:01:12 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 16:01:12 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 16:01:13 [scrapy] DEBUG: Retrying <GET http://tuijianbar.com> (failed 1 times): DNS lookup failed: address 'tuijianbar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2016-04-30 16:01:13 [scrapy] DEBUG: Retrying <GET http://tuijianbar.com> (failed 2 times): DNS lookup failed: address 'tuijianbar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2016-04-30 16:01:13 [scrapy] DEBUG: Gave up retrying <GET http://tuijianbar.com> (failed 3 times): DNS lookup failed: address 'tuijianbar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2016-04-30 16:01:13 [scrapy] ERROR: Error downloading <GET http://tuijianbar.com>: DNS lookup failed: address 'tuijianbar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2016-04-30 16:01:13 [scrapy] INFO: Closing spider (finished)
2016-04-30 16:01:13 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 696,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 8, 1, 13, 896978),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2016, 4, 30, 8, 1, 12, 595330)}
2016-04-30 16:01:13 [scrapy] INFO: Spider closed (finished)
2016-04-30 16:01:57 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 16:01:57 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 16:01:57 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 16:01:58 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 16:01:58 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 16:01:58 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 16:01:58 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 16:01:58 [scrapy] INFO: Spider opened
2016-04-30 16:01:58 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 16:01:58 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 16:01:58 [scrapy] DEBUG: Retrying <GET http://tuijianbar.com> (failed 1 times): DNS lookup failed: address 'tuijianbar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2016-04-30 16:01:58 [scrapy] DEBUG: Retrying <GET http://tuijianbar.com> (failed 2 times): DNS lookup failed: address 'tuijianbar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2016-04-30 16:01:58 [scrapy] DEBUG: Gave up retrying <GET http://tuijianbar.com> (failed 3 times): DNS lookup failed: address 'tuijianbar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2016-04-30 16:01:58 [scrapy] ERROR: Error downloading <GET http://tuijianbar.com>: DNS lookup failed: address 'tuijianbar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2016-04-30 16:01:58 [scrapy] INFO: Closing spider (finished)
2016-04-30 16:01:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 696,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 8, 1, 58, 339594),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2016, 4, 30, 8, 1, 58, 104968)}
2016-04-30 16:01:58 [scrapy] INFO: Spider closed (finished)
2016-04-30 16:04:07 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 16:04:07 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 16:04:07 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 16:04:28 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 16:04:28 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 16:04:28 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 16:04:28 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 16:04:28 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 16:04:28 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 16:04:28 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 16:04:28 [scrapy] INFO: Spider opened
2016-04-30 16:04:28 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 16:04:28 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 16:04:30 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/> (referer: None)
2016-04-30 16:04:31 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/2> (referer: http://wuxianfuli.cc/)
2016-04-30 16:04:34 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/3> (referer: http://wuxianfuli.cc/page/2)
2016-04-30 16:04:38 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/4> (referer: http://wuxianfuli.cc/page/3)
2016-04-30 16:04:39 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/5> (referer: http://wuxianfuli.cc/page/4)
2016-04-30 16:04:43 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/6> (referer: http://wuxianfuli.cc/page/5)
2016-04-30 16:04:45 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/7> (referer: http://wuxianfuli.cc/page/6)
2016-04-30 16:04:48 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/8> (referer: http://wuxianfuli.cc/page/7)
2016-04-30 16:04:51 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/9> (referer: http://wuxianfuli.cc/page/8)
2016-04-30 16:04:53 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/10> (referer: http://wuxianfuli.cc/page/9)
2016-04-30 16:04:55 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/11> (referer: http://wuxianfuli.cc/page/10)
2016-04-30 16:04:57 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/12> (referer: http://wuxianfuli.cc/page/11)
2016-04-30 16:04:58 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/13> (referer: http://wuxianfuli.cc/page/12)
2016-04-30 16:04:59 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/14> (referer: http://wuxianfuli.cc/page/13)
2016-04-30 16:05:01 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/15> (referer: http://wuxianfuli.cc/page/14)
2016-04-30 16:05:03 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/16> (referer: http://wuxianfuli.cc/page/15)
2016-04-30 16:05:07 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/17> (referer: http://wuxianfuli.cc/page/16)
2016-04-30 16:05:10 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/18> (referer: http://wuxianfuli.cc/page/17)
2016-04-30 16:05:11 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/19> (referer: http://wuxianfuli.cc/page/18)
2016-04-30 16:05:12 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/20> (referer: http://wuxianfuli.cc/page/19)
2016-04-30 16:05:14 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/21> (referer: http://wuxianfuli.cc/page/20)
2016-04-30 16:05:15 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/22> (referer: http://wuxianfuli.cc/page/21)
2016-04-30 16:05:18 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/23> (referer: http://wuxianfuli.cc/page/22)
2016-04-30 16:05:19 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/24> (referer: http://wuxianfuli.cc/page/23)
2016-04-30 16:05:21 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/25> (referer: http://wuxianfuli.cc/page/24)
2016-04-30 16:05:25 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/26> (referer: http://wuxianfuli.cc/page/25)
2016-04-30 16:05:27 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/27> (referer: http://wuxianfuli.cc/page/26)
2016-04-30 16:05:28 [scrapy] INFO: Crawled 27 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 16:05:29 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/28> (referer: http://wuxianfuli.cc/page/27)
2016-04-30 16:05:31 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/29> (referer: http://wuxianfuli.cc/page/28)
2016-04-30 16:05:32 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/30> (referer: http://wuxianfuli.cc/page/29)
2016-04-30 16:05:34 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/31> (referer: http://wuxianfuli.cc/page/30)
2016-04-30 16:05:36 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/32> (referer: http://wuxianfuli.cc/page/31)
2016-04-30 16:05:38 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/33> (referer: http://wuxianfuli.cc/page/32)
2016-04-30 16:05:39 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/34> (referer: http://wuxianfuli.cc/page/33)
2016-04-30 16:05:41 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/35> (referer: http://wuxianfuli.cc/page/34)
2016-04-30 16:05:43 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/36> (referer: http://wuxianfuli.cc/page/35)
2016-04-30 16:05:45 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/37> (referer: http://wuxianfuli.cc/page/36)
2016-04-30 16:05:47 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/38> (referer: http://wuxianfuli.cc/page/37)
2016-04-30 16:05:55 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/39> (referer: http://wuxianfuli.cc/page/38)
2016-04-30 16:05:57 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/40> (referer: http://wuxianfuli.cc/page/39)
2016-04-30 16:05:59 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/41> (referer: http://wuxianfuli.cc/page/40)
2016-04-30 16:06:00 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/42> (referer: http://wuxianfuli.cc/page/41)
2016-04-30 16:06:04 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/43> (referer: http://wuxianfuli.cc/page/42)
2016-04-30 16:06:06 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/44> (referer: http://wuxianfuli.cc/page/43)
2016-04-30 16:06:07 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/45> (referer: http://wuxianfuli.cc/page/44)
2016-04-30 16:06:09 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/46> (referer: http://wuxianfuli.cc/page/45)
2016-04-30 16:06:11 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/47> (referer: http://wuxianfuli.cc/page/46)
2016-04-30 16:06:14 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/48> (referer: http://wuxianfuli.cc/page/47)
2016-04-30 16:06:16 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/49> (referer: http://wuxianfuli.cc/page/48)
2016-04-30 16:06:19 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/50> (referer: http://wuxianfuli.cc/page/49)
2016-04-30 16:06:21 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/51> (referer: http://wuxianfuli.cc/page/50)
2016-04-30 16:06:23 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/52> (referer: http://wuxianfuli.cc/page/51)
2016-04-30 16:06:24 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/53> (referer: http://wuxianfuli.cc/page/52)
2016-04-30 16:06:25 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/54> (referer: http://wuxianfuli.cc/page/53)
2016-04-30 16:06:26 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/55> (referer: http://wuxianfuli.cc/page/54)
2016-04-30 16:06:28 [scrapy] INFO: Crawled 55 pages (at 28 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 16:06:28 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/56> (referer: http://wuxianfuli.cc/page/55)
2016-04-30 16:06:30 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/57> (referer: http://wuxianfuli.cc/page/56)
2016-04-30 16:06:32 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/58> (referer: http://wuxianfuli.cc/page/57)
2016-04-30 16:06:33 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/59> (referer: http://wuxianfuli.cc/page/58)
2016-04-30 16:06:35 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/60> (referer: http://wuxianfuli.cc/page/59)
2016-04-30 16:06:36 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/61> (referer: http://wuxianfuli.cc/page/60)
2016-04-30 16:06:37 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/62> (referer: http://wuxianfuli.cc/page/61)
2016-04-30 16:06:38 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/63> (referer: http://wuxianfuli.cc/page/62)
2016-04-30 16:06:40 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/64> (referer: http://wuxianfuli.cc/page/63)
2016-04-30 16:06:42 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/65> (referer: http://wuxianfuli.cc/page/64)
2016-04-30 16:06:43 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/66> (referer: http://wuxianfuli.cc/page/65)
2016-04-30 16:06:44 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/67> (referer: http://wuxianfuli.cc/page/66)
2016-04-30 16:06:45 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/68> (referer: http://wuxianfuli.cc/page/67)
2016-04-30 16:06:48 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/69> (referer: http://wuxianfuli.cc/page/68)
2016-04-30 16:06:52 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/70> (referer: http://wuxianfuli.cc/page/69)
2016-04-30 16:06:54 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/71> (referer: http://wuxianfuli.cc/page/70)
2016-04-30 16:06:56 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/72> (referer: http://wuxianfuli.cc/page/71)
2016-04-30 16:06:58 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/73> (referer: http://wuxianfuli.cc/page/72)
2016-04-30 16:07:00 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/74> (referer: http://wuxianfuli.cc/page/73)
2016-04-30 16:07:02 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/75> (referer: http://wuxianfuli.cc/page/74)
2016-04-30 16:07:04 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/76> (referer: http://wuxianfuli.cc/page/75)
2016-04-30 16:07:06 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/77> (referer: http://wuxianfuli.cc/page/76)
2016-04-30 16:07:08 [scrapy] DEBUG: Crawled (200) <GET http://wuxianfuli.cc/page/78> (referer: http://wuxianfuli.cc/page/77)
2016-04-30 16:07:08 [scrapy] INFO: Closing spider (finished)
2016-04-30 16:07:08 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 26465,
 'downloader/request_count': 78,
 'downloader/request_method_count/GET': 78,
 'downloader/response_bytes': 898753,
 'downloader/response_count': 78,
 'downloader/response_status_count/200': 78,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 8, 7, 8, 522359),
 'log_count/DEBUG': 79,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'request_depth_max': 77,
 'response_received_count': 78,
 'scheduler/dequeued': 78,
 'scheduler/dequeued/memory': 78,
 'scheduler/enqueued': 78,
 'scheduler/enqueued/memory': 78,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 8, 4, 28, 270029)}
2016-04-30 16:07:08 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:41:27 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:41:27 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:41:27 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:41:27 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:41:27 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:41:27 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:41:27 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:41:27 [scrapy] INFO: Spider opened
2016-04-30 17:41:27 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:41:27 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:41:29 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:41:32 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/2> (referer: http://www.flkong.net) ['partial']
2016-04-30 17:41:34 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/3> (referer: http://www.flkong.net/page/2) ['partial']
2016-04-30 17:41:36 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/4> (referer: http://www.flkong.net/page/3) ['partial']
2016-04-30 17:41:38 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/5> (referer: http://www.flkong.net/page/4) ['partial']
2016-04-30 17:41:42 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/6> (referer: http://www.flkong.net/page/5) ['partial']
2016-04-30 17:41:44 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/7> (referer: http://www.flkong.net/page/6) ['partial']
2016-04-30 17:41:46 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/8> (referer: http://www.flkong.net/page/7) ['partial']
2016-04-30 17:41:48 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/9> (referer: http://www.flkong.net/page/8) ['partial']
2016-04-30 17:41:50 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/10> (referer: http://www.flkong.net/page/9) ['partial']
2016-04-30 17:41:53 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/11> (referer: http://www.flkong.net/page/10) ['partial']
2016-04-30 17:41:57 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/12> (referer: http://www.flkong.net/page/11) ['partial']
2016-04-30 17:41:59 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/13> (referer: http://www.flkong.net/page/12) ['partial']
2016-04-30 17:42:01 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 17:42:01 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 17:42:01 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2016-04-30 17:42:01 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/14> (referer: http://www.flkong.net/page/13) ['partial']
2016-04-30 17:42:22 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:42:22 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:42:22 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:42:22 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:42:22 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:42:22 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:42:22 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:42:22 [scrapy] INFO: Spider opened
2016-04-30 17:42:22 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:42:22 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:42:24 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:42:27 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/2> (referer: http://www.flkong.net) ['partial']
2016-04-30 17:42:30 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/3> (referer: http://www.flkong.net/page/2) ['partial']
2016-04-30 17:42:32 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/4> (referer: http://www.flkong.net/page/3) ['partial']
2016-04-30 17:42:35 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/5> (referer: http://www.flkong.net/page/4) ['partial']
2016-04-30 17:42:37 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/6> (referer: http://www.flkong.net/page/5) ['partial']
2016-04-30 17:42:39 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/7> (referer: http://www.flkong.net/page/6) ['partial']
2016-04-30 17:42:44 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/8> (referer: http://www.flkong.net/page/7) ['partial']
2016-04-30 17:42:46 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/9> (referer: http://www.flkong.net/page/8) ['partial']
2016-04-30 17:42:47 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 17:42:47 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 17:42:47 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2016-04-30 17:42:47 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/10> (referer: http://www.flkong.net/page/9) ['partial']
2016-04-30 17:43:15 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:43:15 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:43:15 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:43:15 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:43:15 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:43:15 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:43:15 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:43:15 [scrapy] INFO: Spider opened
2016-04-30 17:43:15 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:43:15 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:43:17 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:43:19 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 17:43:19 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 17:43:20 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/2> (referer: http://www.flkong.net) ['partial']
2016-04-30 17:43:20 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 502,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 68872,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 43, 20, 574298),
 'log_count/DEBUG': 3,
 'log_count/INFO': 8,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2016, 4, 30, 9, 43, 15, 465947)}
2016-04-30 17:43:20 [scrapy] INFO: Spider closed (shutdown)
2016-04-30 17:43:40 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:43:40 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:43:40 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:43:40 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:43:40 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:43:40 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:43:40 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:43:40 [scrapy] INFO: Spider opened
2016-04-30 17:43:40 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:43:40 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:43:43 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:43:43 [scrapy] ERROR: Spider error processing <GET http://www.flkong.net> (referer: None)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiao/project/fuli/src/fuli_spiders/fuli_spiders/spiders/flkong.py", line 27, in parse
    img = item.xpath('p[2]/a/img/@src').extract()[0]
IndexError: list index out of range
2016-04-30 17:43:43 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:43:43 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 43, 43, 821770),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 43, 40, 433648)}
2016-04-30 17:43:43 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:44:31 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:44:31 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:44:31 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:44:31 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:44:31 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:44:31 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:44:31 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:44:31 [scrapy] INFO: Spider opened
2016-04-30 17:44:31 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:44:31 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:44:34 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:44:34 [scrapy] ERROR: Spider error processing <GET http://www.flkong.net> (referer: None)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiao/project/fuli/src/fuli_spiders/fuli_spiders/spiders/flkong.py", line 27, in parse
    img = item.xpath('p[2]/a/img/@data-original').extract()[0]
IndexError: list index out of range
2016-04-30 17:44:34 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:44:34 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 44, 34, 256649),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 44, 31, 758717)}
2016-04-30 17:44:34 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:46:28 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:46:28 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:46:28 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:46:28 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:46:28 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:46:28 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:46:28 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:46:28 [scrapy] INFO: Spider opened
2016-04-30 17:46:28 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:46:28 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:46:30 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:46:30 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:46:30 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 46, 30, 880996),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnicodeEncodeError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 46, 28, 711712)}
2016-04-30 17:46:30 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:47:06 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:47:06 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:47:06 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:47:06 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:47:06 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:47:06 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:47:06 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:47:06 [scrapy] INFO: Spider opened
2016-04-30 17:47:06 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:47:06 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:47:09 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:47:09 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:47:09 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 47, 9, 411702),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnicodeEncodeError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 47, 6, 421150)}
2016-04-30 17:47:09 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:47:31 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:47:31 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:47:31 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:47:31 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:47:31 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:47:31 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:47:31 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:47:31 [scrapy] INFO: Spider opened
2016-04-30 17:47:31 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:47:31 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:47:33 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:47:33 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:47:33 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 47, 33, 701472),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnicodeEncodeError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 47, 31, 753022)}
2016-04-30 17:47:33 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:48:44 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:48:44 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:48:44 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:48:44 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:48:44 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:48:44 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:48:44 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:48:44 [scrapy] INFO: Spider opened
2016-04-30 17:48:44 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:48:44 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:48:46 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:48:46 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:48:46 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 48, 46, 864905),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnicodeEncodeError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 48, 44, 279250)}
2016-04-30 17:48:46 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:49:21 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:49:21 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:49:21 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:49:21 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:49:21 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:49:21 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:49:21 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:49:21 [scrapy] INFO: Spider opened
2016-04-30 17:49:21 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:49:21 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:49:23 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:49:23 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:49:23 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 49, 23, 775480),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 49, 21, 794677)}
2016-04-30 17:49:23 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:49:43 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:49:43 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:49:43 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:49:43 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:49:43 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:49:43 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:49:43 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:49:43 [scrapy] INFO: Spider opened
2016-04-30 17:49:43 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:49:43 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:49:45 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:49:45 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:49:45 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 49, 45, 581174),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 49, 43, 323639)}
2016-04-30 17:49:45 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:49:59 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:49:59 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:49:59 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:49:59 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:49:59 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:49:59 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:49:59 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:49:59 [scrapy] INFO: Spider opened
2016-04-30 17:49:59 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:49:59 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:50:04 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:50:04 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:50:04 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 50, 4, 737964),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 49, 59, 227048)}
2016-04-30 17:50:04 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:50:17 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:50:17 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:50:17 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:50:17 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:50:17 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:50:17 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:50:17 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:50:17 [scrapy] INFO: Spider opened
2016-04-30 17:50:17 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:50:17 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:50:22 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:50:22 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:50:22 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 50, 22, 219342),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnicodeEncodeError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 50, 17, 471493)}
2016-04-30 17:50:22 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:51:27 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:51:27 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:51:27 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:51:27 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:51:27 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:51:27 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:51:27 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:51:27 [scrapy] INFO: Spider opened
2016-04-30 17:51:27 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:51:27 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:51:29 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:51:29 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:51:29 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 51, 29, 490188),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 51, 27, 137731)}
2016-04-30 17:51:29 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:51:54 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:51:54 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:51:54 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:51:54 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:51:54 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:51:54 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:51:54 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:51:54 [scrapy] INFO: Spider opened
2016-04-30 17:51:54 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:51:54 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:51:56 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:51:56 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:51:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 51, 56, 955951),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 51, 54, 352756)}
2016-04-30 17:51:56 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:52:29 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:52:29 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:52:29 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:52:29 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:52:29 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:52:29 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:52:29 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:52:29 [scrapy] INFO: Spider opened
2016-04-30 17:52:29 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:52:29 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:52:31 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:52:31 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:52:31 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 52, 31, 650794),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 52, 29, 311681)}
2016-04-30 17:52:31 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:52:44 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:52:44 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:52:44 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:52:44 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:52:44 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:52:44 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:52:44 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:52:44 [scrapy] INFO: Spider opened
2016-04-30 17:52:44 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:52:44 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:52:46 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:52:46 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:52:46 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 52, 46, 966294),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 52, 44, 121074)}
2016-04-30 17:52:46 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:53:08 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:53:08 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:53:08 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:53:08 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:53:08 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:53:08 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:53:08 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:53:08 [scrapy] INFO: Spider opened
2016-04-30 17:53:08 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:53:08 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:53:10 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:53:10 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:53:10 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 232,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36359,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 53, 10, 935622),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 53, 8, 991075)}
2016-04-30 17:53:10 [scrapy] INFO: Spider closed (finished)
2016-04-30 17:53:21 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:53:21 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:53:21 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:53:21 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:53:21 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:53:21 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:53:21 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:53:21 [scrapy] INFO: Spider opened
2016-04-30 17:53:21 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:53:21 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:53:25 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:53:27 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/2> (referer: http://www.flkong.net) ['partial']
2016-04-30 17:53:29 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/3> (referer: http://www.flkong.net/page/2) ['partial']
2016-04-30 17:53:33 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/4> (referer: http://www.flkong.net/page/3) ['partial']
2016-04-30 17:53:35 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/5> (referer: http://www.flkong.net/page/4) ['partial']
2016-04-30 17:53:37 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/6> (referer: http://www.flkong.net/page/5) ['partial']
2016-04-30 17:53:37 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 17:53:37 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 17:53:38 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/7> (referer: http://www.flkong.net/page/6) ['partial']
2016-04-30 17:53:39 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1887,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 232008,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 53, 39, 96722),
 'log_count/DEBUG': 8,
 'log_count/INFO': 8,
 'request_depth_max': 7,
 'response_received_count': 7,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2016, 4, 30, 9, 53, 21, 203237)}
2016-04-30 17:53:39 [scrapy] INFO: Spider closed (shutdown)
2016-04-30 17:53:48 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 17:53:48 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 17:53:48 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 17:53:48 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 17:53:48 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 17:53:48 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 17:53:48 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 17:53:48 [scrapy] INFO: Spider opened
2016-04-30 17:53:48 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:53:48 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 17:53:50 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net> (referer: None) ['partial']
2016-04-30 17:53:52 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/2> (referer: http://www.flkong.net) ['partial']
2016-04-30 17:53:55 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/3> (referer: http://www.flkong.net/page/2) ['partial']
2016-04-30 17:53:57 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/4> (referer: http://www.flkong.net/page/3) ['partial']
2016-04-30 17:53:59 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/5> (referer: http://www.flkong.net/page/4) ['partial']
2016-04-30 17:54:01 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/6> (referer: http://www.flkong.net/page/5) ['partial']
2016-04-30 17:54:03 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/7> (referer: http://www.flkong.net/page/6) ['partial']
2016-04-30 17:54:08 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/8> (referer: http://www.flkong.net/page/7) ['partial']
2016-04-30 17:54:10 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/9> (referer: http://www.flkong.net/page/8) ['partial']
2016-04-30 17:54:12 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/10> (referer: http://www.flkong.net/page/9) ['partial']
2016-04-30 17:54:15 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/11> (referer: http://www.flkong.net/page/10) ['partial']
2016-04-30 17:54:17 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/12> (referer: http://www.flkong.net/page/11) ['partial']
2016-04-30 17:54:21 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/13> (referer: http://www.flkong.net/page/12) ['partial']
2016-04-30 17:54:22 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/14> (referer: http://www.flkong.net/page/13) ['partial']
2016-04-30 17:54:25 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/15> (referer: http://www.flkong.net/page/14) ['partial']
2016-04-30 17:54:27 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/16> (referer: http://www.flkong.net/page/15) ['partial']
2016-04-30 17:54:29 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/17> (referer: http://www.flkong.net/page/16) ['partial']
2016-04-30 17:54:31 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/18> (referer: http://www.flkong.net/page/17) ['partial']
2016-04-30 17:54:33 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/19> (referer: http://www.flkong.net/page/18) ['partial']
2016-04-30 17:54:35 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/20> (referer: http://www.flkong.net/page/19) ['partial']
2016-04-30 17:54:37 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/21> (referer: http://www.flkong.net/page/20) ['partial']
2016-04-30 17:54:40 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/22> (referer: http://www.flkong.net/page/21) ['partial']
2016-04-30 17:54:42 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/23> (referer: http://www.flkong.net/page/22) ['partial']
2016-04-30 17:54:44 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/24> (referer: http://www.flkong.net/page/23) ['partial']
2016-04-30 17:54:48 [scrapy] INFO: Crawled 24 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:54:50 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/25> (referer: http://www.flkong.net/page/24) ['partial']
2016-04-30 17:54:52 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/26> (referer: http://www.flkong.net/page/25) ['partial']
2016-04-30 17:54:57 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/27> (referer: http://www.flkong.net/page/26) ['partial']
2016-04-30 17:54:59 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/28> (referer: http://www.flkong.net/page/27) ['partial']
2016-04-30 17:55:02 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/29> (referer: http://www.flkong.net/page/28) ['partial']
2016-04-30 17:55:04 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/30> (referer: http://www.flkong.net/page/29) ['partial']
2016-04-30 17:55:06 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/31> (referer: http://www.flkong.net/page/30) ['partial']
2016-04-30 17:55:08 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/32> (referer: http://www.flkong.net/page/31) ['partial']
2016-04-30 17:55:10 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/33> (referer: http://www.flkong.net/page/32) ['partial']
2016-04-30 17:55:13 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/34> (referer: http://www.flkong.net/page/33) ['partial']
2016-04-30 17:55:16 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/35> (referer: http://www.flkong.net/page/34) ['partial']
2016-04-30 17:55:19 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/36> (referer: http://www.flkong.net/page/35) ['partial']
2016-04-30 17:55:22 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/37> (referer: http://www.flkong.net/page/36) ['partial']
2016-04-30 17:55:28 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/38> (referer: http://www.flkong.net/page/37) ['partial']
2016-04-30 17:55:30 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/39> (referer: http://www.flkong.net/page/38) ['partial']
2016-04-30 17:55:32 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/40> (referer: http://www.flkong.net/page/39) ['partial']
2016-04-30 17:55:35 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/41> (referer: http://www.flkong.net/page/40) ['partial']
2016-04-30 17:55:37 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/42> (referer: http://www.flkong.net/page/41) ['partial']
2016-04-30 17:55:39 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/43> (referer: http://www.flkong.net/page/42) ['partial']
2016-04-30 17:55:41 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/44> (referer: http://www.flkong.net/page/43) ['partial']
2016-04-30 17:55:43 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/45> (referer: http://www.flkong.net/page/44) ['partial']
2016-04-30 17:55:45 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/46> (referer: http://www.flkong.net/page/45) ['partial']
2016-04-30 17:55:48 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/47> (referer: http://www.flkong.net/page/46) ['partial']
2016-04-30 17:55:48 [scrapy] INFO: Crawled 47 pages (at 23 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:55:50 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/48> (referer: http://www.flkong.net/page/47) ['partial']
2016-04-30 17:55:53 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/49> (referer: http://www.flkong.net/page/48) ['partial']
2016-04-30 17:55:55 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/50> (referer: http://www.flkong.net/page/49) ['partial']
2016-04-30 17:55:59 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/51> (referer: http://www.flkong.net/page/50) ['partial']
2016-04-30 17:56:01 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/52> (referer: http://www.flkong.net/page/51) ['partial']
2016-04-30 17:56:04 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/53> (referer: http://www.flkong.net/page/52) ['partial']
2016-04-30 17:56:06 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/54> (referer: http://www.flkong.net/page/53) ['partial']
2016-04-30 17:56:10 [scrapy] DEBUG: Retrying <GET http://www.flkong.net/page/55> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2016-04-30 17:56:13 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/55> (referer: http://www.flkong.net/page/54) ['partial']
2016-04-30 17:56:17 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/56> (referer: http://www.flkong.net/page/55) ['partial']
2016-04-30 17:56:20 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/57> (referer: http://www.flkong.net/page/56) ['partial']
2016-04-30 17:56:22 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/58> (referer: http://www.flkong.net/page/57) ['partial']
2016-04-30 17:56:30 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/59> (referer: http://www.flkong.net/page/58) ['partial']
2016-04-30 17:56:33 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/60> (referer: http://www.flkong.net/page/59) ['partial']
2016-04-30 17:56:39 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/61> (referer: http://www.flkong.net/page/60) ['partial']
2016-04-30 17:56:42 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/62> (referer: http://www.flkong.net/page/61) ['partial']
2016-04-30 17:56:45 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/63> (referer: http://www.flkong.net/page/62) ['partial']
2016-04-30 17:56:48 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/64> (referer: http://www.flkong.net/page/63) ['partial']
2016-04-30 17:56:48 [scrapy] INFO: Crawled 64 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 17:56:51 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/65> (referer: http://www.flkong.net/page/64) ['partial']
2016-04-30 17:56:54 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/66> (referer: http://www.flkong.net/page/65) ['partial']
2016-04-30 17:56:59 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/67> (referer: http://www.flkong.net/page/66) ['partial']
2016-04-30 17:57:02 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/68> (referer: http://www.flkong.net/page/67) ['partial']
2016-04-30 17:57:04 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/69> (referer: http://www.flkong.net/page/68) ['partial']
2016-04-30 17:57:07 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/70> (referer: http://www.flkong.net/page/69) ['partial']
2016-04-30 17:57:11 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/71> (referer: http://www.flkong.net/page/70) ['partial']
2016-04-30 17:57:14 [scrapy] DEBUG: Crawled (200) <GET http://www.flkong.net/page/72> (referer: http://www.flkong.net/page/71) ['partial']
2016-04-30 17:57:14 [scrapy] INFO: Closing spider (finished)
2016-04-30 17:57:14 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 20296,
 'downloader/request_count': 73,
 'downloader/request_method_count/GET': 73,
 'downloader/response_bytes': 2371545,
 'downloader/response_count': 72,
 'downloader/response_status_count/200': 72,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 9, 57, 14, 426509),
 'log_count/DEBUG': 74,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 71,
 'response_received_count': 72,
 'scheduler/dequeued': 73,
 'scheduler/dequeued/memory': 73,
 'scheduler/enqueued': 73,
 'scheduler/enqueued/memory': 73,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 9, 53, 48, 875395)}
2016-04-30 17:57:14 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:40:12 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:40:12 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:40:12 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:40:31 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:40:31 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:40:31 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:40:31 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:40:31 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:40:31 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:40:31 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:40:31 [scrapy] INFO: Spider opened
2016-04-30 18:40:31 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:40:31 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:40:33 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:40:33 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:40:33 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9077,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 40, 33, 381145),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 40, 31, 858127)}
2016-04-30 18:40:33 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:40:47 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:40:47 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:40:47 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:40:47 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:40:47 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:40:47 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:40:47 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:40:47 [scrapy] INFO: Spider opened
2016-04-30 18:40:47 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:40:47 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:40:49 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:40:49 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:40:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9080,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 40, 49, 349080),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 40, 47, 478770)}
2016-04-30 18:40:49 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:41:03 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:41:03 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:41:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:41:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:41:03 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:41:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:41:03 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:41:03 [scrapy] INFO: Spider opened
2016-04-30 18:41:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:41:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:41:04 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:41:05 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:41:05 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9078,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 41, 5, 24727),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 41, 3, 905830)}
2016-04-30 18:41:05 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:42:36 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:42:36 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:42:36 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:42:36 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:42:36 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:42:36 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:42:36 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:42:36 [scrapy] INFO: Spider opened
2016-04-30 18:42:36 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:42:36 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:42:37 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:42:38 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:42:38 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9076,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 42, 38, 93459),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 42, 36, 861972)}
2016-04-30 18:42:38 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:43:15 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:43:15 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:43:15 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:43:15 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:43:15 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:43:15 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:43:15 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:43:15 [scrapy] INFO: Spider opened
2016-04-30 18:43:15 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:43:15 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:43:17 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:43:17 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:43:17 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9077,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 43, 17, 150575),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 43, 15, 959631)}
2016-04-30 18:43:17 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:44:51 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:44:51 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:44:51 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:44:51 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:44:51 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:44:51 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:44:51 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:44:51 [scrapy] INFO: Spider opened
2016-04-30 18:44:51 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:44:51 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:44:52 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:44:52 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:44:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9077,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 44, 52, 648691),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 44, 51, 392103)}
2016-04-30 18:44:52 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:45:13 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:45:13 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:45:13 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:45:14 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:45:14 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:45:14 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:45:14 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:45:14 [scrapy] INFO: Spider opened
2016-04-30 18:45:14 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:45:14 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:45:14 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 18:45:14 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 18:45:15 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:45:15 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9074,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 45, 15, 381443),
 'log_count/DEBUG': 2,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 45, 14, 86040)}
2016-04-30 18:45:15 [scrapy] INFO: Spider closed (shutdown)
2016-04-30 18:46:10 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:46:10 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:46:10 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:46:10 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:46:10 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:46:10 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:46:10 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:46:10 [scrapy] INFO: Spider opened
2016-04-30 18:46:10 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:46:10 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:46:11 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:46:11 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:46:11 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9078,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 46, 11, 892142),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 46, 10, 360197)}
2016-04-30 18:46:11 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:47:36 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:47:36 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:47:36 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:47:36 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:47:36 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:47:36 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:47:36 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:47:36 [scrapy] INFO: Spider opened
2016-04-30 18:47:36 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:47:36 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:47:39 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:47:39 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:47:39 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9078,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 47, 39, 536059),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 47, 36, 993000)}
2016-04-30 18:47:39 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:49:53 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:49:53 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:49:53 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:49:53 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:49:53 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:49:53 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:49:53 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:49:53 [scrapy] INFO: Spider opened
2016-04-30 18:49:53 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:49:53 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:49:55 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:49:56 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:49:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9074,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 49, 56, 32225),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 49, 53, 546725)}
2016-04-30 18:49:56 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:50:18 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:50:18 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:50:18 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:50:18 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:50:18 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:50:18 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:50:18 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:50:18 [scrapy] INFO: Spider opened
2016-04-30 18:50:18 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:50:18 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:50:19 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:50:19 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:50:19 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 228,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 9078,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 50, 19, 929557),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 50, 18, 486762)}
2016-04-30 18:50:19 [scrapy] INFO: Spider closed (finished)
2016-04-30 18:52:30 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:52:30 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:52:30 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:52:30 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:52:30 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:52:30 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:52:30 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:52:30 [scrapy] INFO: Spider opened
2016-04-30 18:52:30 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:52:30 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:52:31 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:52:32 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/2> (referer: https://youdian.in/)
2016-04-30 18:52:33 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/3> (referer: https://youdian.in/page/2)
2016-04-30 18:52:34 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 18:52:34 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 18:52:34 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2016-04-30 18:55:55 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:55:55 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:55:55 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:55:55 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:55:55 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:55:55 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:55:55 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:55:55 [scrapy] INFO: Spider opened
2016-04-30 18:55:55 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:55:55 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:55:57 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:55:58 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/2> (referer: https://youdian.in/)
2016-04-30 18:55:58 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/3> (referer: https://youdian.in/page/2)
2016-04-30 18:55:59 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 18:55:59 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 18:55:59 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/4> (referer: https://youdian.in/page/3)
2016-04-30 18:55:59 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1188,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38318,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 55, 59, 701175),
 'log_count/DEBUG': 5,
 'log_count/INFO': 8,
 'request_depth_max': 4,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2016, 4, 30, 10, 55, 55, 837287)}
2016-04-30 18:55:59 [scrapy] INFO: Spider closed (shutdown)
2016-04-30 18:56:14 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:56:14 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:56:14 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:56:14 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:56:14 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:56:14 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:56:14 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:56:14 [scrapy] INFO: Spider opened
2016-04-30 18:56:14 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:56:14 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:56:18 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:56:19 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 18:56:19 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 18:56:19 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2016-04-30 18:56:59 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:56:59 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:56:59 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:56:59 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:56:59 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:56:59 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:56:59 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:56:59 [scrapy] INFO: Spider opened
2016-04-30 18:56:59 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:56:59 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:57:01 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:57:02 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/2> (referer: https://youdian.in/)
2016-04-30 18:57:03 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-04-30 18:57:03 [scrapy] INFO: Closing spider (shutdown)
2016-04-30 18:57:03 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2016-04-30 18:57:29 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 18:57:29 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 18:57:29 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 18:57:29 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 18:57:29 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 18:57:29 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 18:57:29 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 18:57:29 [scrapy] INFO: Spider opened
2016-04-30 18:57:29 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 18:57:29 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 18:57:31 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/> (referer: None)
2016-04-30 18:57:32 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/2> (referer: https://youdian.in/)
2016-04-30 18:57:32 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/3> (referer: https://youdian.in/page/2)
2016-04-30 18:57:33 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/4> (referer: https://youdian.in/page/3)
2016-04-30 18:57:34 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/5> (referer: https://youdian.in/page/4)
2016-04-30 18:57:36 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/6> (referer: https://youdian.in/page/5)
2016-04-30 18:57:37 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/7> (referer: https://youdian.in/page/6)
2016-04-30 18:57:37 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/8> (referer: https://youdian.in/page/7)
2016-04-30 18:57:38 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/9> (referer: https://youdian.in/page/8)
2016-04-30 18:57:39 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/10> (referer: https://youdian.in/page/9)
2016-04-30 18:57:40 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/11> (referer: https://youdian.in/page/10)
2016-04-30 18:57:40 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/12> (referer: https://youdian.in/page/11)
2016-04-30 18:57:41 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/13> (referer: https://youdian.in/page/12)
2016-04-30 18:57:42 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/14> (referer: https://youdian.in/page/13)
2016-04-30 18:57:42 [scrapy] DEBUG: Crawled (200) <GET https://youdian.in/page/15> (referer: https://youdian.in/page/14)
2016-04-30 18:57:43 [scrapy] INFO: Closing spider (finished)
2016-04-30 18:57:43 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4741,
 'downloader/request_count': 15,
 'downloader/request_method_count/GET': 15,
 'downloader/response_bytes': 142756,
 'downloader/response_count': 15,
 'downloader/response_status_count/200': 15,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 10, 57, 43, 75848),
 'log_count/DEBUG': 16,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 14,
 'response_received_count': 15,
 'scheduler/dequeued': 15,
 'scheduler/dequeued/memory': 15,
 'scheduler/enqueued': 15,
 'scheduler/enqueued/memory': 15,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2016, 4, 30, 10, 57, 29, 848690)}
2016-04-30 18:57:43 [scrapy] INFO: Spider closed (finished)
2016-04-30 19:01:39 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 19:01:39 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 19:01:39 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 19:01:44 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 19:01:44 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 19:01:44 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 19:01:44 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 19:01:44 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 19:01:44 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 19:01:44 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 19:01:44 [scrapy] INFO: Spider opened
2016-04-30 19:01:44 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 19:01:44 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 19:01:48 [scrapy] DEBUG: Retrying <GET http://www.acctv.net/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2016-04-30 19:01:52 [scrapy] DEBUG: Retrying <GET http://www.acctv.net/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2016-04-30 19:01:56 [scrapy] DEBUG: Gave up retrying <GET http://www.acctv.net/> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2016-04-30 19:01:56 [scrapy] ERROR: Error downloading <GET http://www.acctv.net/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2016-04-30 19:01:56 [scrapy] INFO: Closing spider (finished)
2016-04-30 19:01:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'downloader/request_bytes': 693,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 11, 1, 56, 661953),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2016, 4, 30, 11, 1, 44, 426311)}
2016-04-30 19:01:56 [scrapy] INFO: Spider closed (finished)
2016-04-30 19:02:17 [scrapy] INFO: Scrapy 1.0.5 started (bot: fuli_spiders)
2016-04-30 19:02:17 [scrapy] INFO: Optional features available: ssl, http11
2016-04-30 19:02:17 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'fuli_spiders.spiders', 'SPIDER_MODULES': ['fuli_spiders.spiders'], 'LOG_FILE': 'fuli_spiders.log', 'USER_AGENT': 'Baiduspider (+http://www.baidu.com/search/spider.htm)', 'BOT_NAME': 'fuli_spiders'}
2016-04-30 19:02:17 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-04-30 19:02:17 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-04-30 19:02:17 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-04-30 19:02:17 [scrapy] INFO: Enabled item pipelines: 
2016-04-30 19:02:17 [scrapy] INFO: Spider opened
2016-04-30 19:02:17 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-04-30 19:02:17 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-04-30 19:02:21 [scrapy] DEBUG: Retrying <GET http://www.acctv.net/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2016-04-30 19:02:25 [scrapy] DEBUG: Retrying <GET http://www.acctv.net/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2016-04-30 19:02:29 [scrapy] DEBUG: Gave up retrying <GET http://www.acctv.net/> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2016-04-30 19:02:29 [scrapy] ERROR: Error downloading <GET http://www.acctv.net/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2016-04-30 19:02:30 [scrapy] INFO: Closing spider (finished)
2016-04-30 19:02:30 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'downloader/request_bytes': 693,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 4, 30, 11, 2, 30, 88466),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2016, 4, 30, 11, 2, 17, 849220)}
2016-04-30 19:02:30 [scrapy] INFO: Spider closed (finished)
